{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter tuning of RF Classifier on a ISOLET Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4jpDeXo/om6zj1N2+evGY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dotmanjohn/kosh/blob/master/Hyperparameter_Tuning_of_RF_Classifier_on_a_ISOLET_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndGL63Y6kLwr",
        "colab_type": "text"
      },
      "source": [
        "#Training a Random Forest Classifier with Hyperparameter Tuning on a ISOLET Dataset\n",
        "You are working for a technology company and they are planning to launch a new voice assistant product. You have been tasked with building a classification model that will recognize the letters spelled out by a user based on the signal frequencies captured. Each sound can be captured and represented as a signal composed of multiple frequencies.\n",
        "\n",
        "We will carry out hyperparameter tuning and select the model with the set of hyperparameters that gives the best performance (least overfitting model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhq8-YI4_VmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp9bgc55_bUp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "6e0088c2-7395-4cd4-b710-0ec05c8eaa4a"
      },
      "source": [
        "file_url = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter04/Dataset/phpB0xrNj.csv'\n",
        "df = pd.read_csv(file_url)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>f15</th>\n",
              "      <th>f16</th>\n",
              "      <th>f17</th>\n",
              "      <th>f18</th>\n",
              "      <th>f19</th>\n",
              "      <th>f20</th>\n",
              "      <th>f21</th>\n",
              "      <th>f22</th>\n",
              "      <th>f23</th>\n",
              "      <th>f24</th>\n",
              "      <th>f25</th>\n",
              "      <th>f26</th>\n",
              "      <th>f27</th>\n",
              "      <th>f28</th>\n",
              "      <th>f29</th>\n",
              "      <th>f30</th>\n",
              "      <th>f31</th>\n",
              "      <th>f32</th>\n",
              "      <th>f33</th>\n",
              "      <th>f34</th>\n",
              "      <th>f35</th>\n",
              "      <th>f36</th>\n",
              "      <th>f37</th>\n",
              "      <th>f38</th>\n",
              "      <th>f39</th>\n",
              "      <th>f40</th>\n",
              "      <th>...</th>\n",
              "      <th>f579</th>\n",
              "      <th>f580</th>\n",
              "      <th>f581</th>\n",
              "      <th>f582</th>\n",
              "      <th>f583</th>\n",
              "      <th>f584</th>\n",
              "      <th>f585</th>\n",
              "      <th>f586</th>\n",
              "      <th>f587</th>\n",
              "      <th>f588</th>\n",
              "      <th>f589</th>\n",
              "      <th>f590</th>\n",
              "      <th>f591</th>\n",
              "      <th>f592</th>\n",
              "      <th>f593</th>\n",
              "      <th>f594</th>\n",
              "      <th>f595</th>\n",
              "      <th>f596</th>\n",
              "      <th>f597</th>\n",
              "      <th>f598</th>\n",
              "      <th>f599</th>\n",
              "      <th>f600</th>\n",
              "      <th>f601</th>\n",
              "      <th>f602</th>\n",
              "      <th>f603</th>\n",
              "      <th>f604</th>\n",
              "      <th>f605</th>\n",
              "      <th>f606</th>\n",
              "      <th>f607</th>\n",
              "      <th>f608</th>\n",
              "      <th>f609</th>\n",
              "      <th>f610</th>\n",
              "      <th>f611</th>\n",
              "      <th>f612</th>\n",
              "      <th>f613</th>\n",
              "      <th>f614</th>\n",
              "      <th>f615</th>\n",
              "      <th>f616</th>\n",
              "      <th>f617</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.4394</td>\n",
              "      <td>-0.0930</td>\n",
              "      <td>0.1718</td>\n",
              "      <td>0.4620</td>\n",
              "      <td>0.6226</td>\n",
              "      <td>0.4704</td>\n",
              "      <td>0.3578</td>\n",
              "      <td>0.0478</td>\n",
              "      <td>-0.1184</td>\n",
              "      <td>-0.2310</td>\n",
              "      <td>-0.2958</td>\n",
              "      <td>-0.2704</td>\n",
              "      <td>-0.2620</td>\n",
              "      <td>-0.2170</td>\n",
              "      <td>-0.0874</td>\n",
              "      <td>-0.0564</td>\n",
              "      <td>0.0254</td>\n",
              "      <td>0.0958</td>\n",
              "      <td>0.4226</td>\n",
              "      <td>0.6648</td>\n",
              "      <td>0.9184</td>\n",
              "      <td>0.9718</td>\n",
              "      <td>0.9324</td>\n",
              "      <td>0.7070</td>\n",
              "      <td>0.6986</td>\n",
              "      <td>0.7550</td>\n",
              "      <td>0.8816</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9380</td>\n",
              "      <td>0.8450</td>\n",
              "      <td>0.7268</td>\n",
              "      <td>0.5578</td>\n",
              "      <td>-0.4330</td>\n",
              "      <td>-0.1982</td>\n",
              "      <td>0.1270</td>\n",
              "      <td>0.3666</td>\n",
              "      <td>0.4496</td>\n",
              "      <td>0.4258</td>\n",
              "      <td>0.2646</td>\n",
              "      <td>-0.0368</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.1334</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.0770</td>\n",
              "      <td>0.0512</td>\n",
              "      <td>0.2564</td>\n",
              "      <td>0.5642</td>\n",
              "      <td>0.4872</td>\n",
              "      <td>0.0770</td>\n",
              "      <td>0.4358</td>\n",
              "      <td>0.7436</td>\n",
              "      <td>0.5128</td>\n",
              "      <td>0.6666</td>\n",
              "      <td>0.6410</td>\n",
              "      <td>0.6154</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8206</td>\n",
              "      <td>0.6410</td>\n",
              "      <td>0.3590</td>\n",
              "      <td>0.6924</td>\n",
              "      <td>0.4358</td>\n",
              "      <td>0.1538</td>\n",
              "      <td>0.4616</td>\n",
              "      <td>0.6154</td>\n",
              "      <td>0.3334</td>\n",
              "      <td>0.3334</td>\n",
              "      <td>0.4102</td>\n",
              "      <td>0.2052</td>\n",
              "      <td>0.3846</td>\n",
              "      <td>0.3590</td>\n",
              "      <td>0.5898</td>\n",
              "      <td>0.3334</td>\n",
              "      <td>0.6410</td>\n",
              "      <td>0.5898</td>\n",
              "      <td>-0.4872</td>\n",
              "      <td>'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.4348</td>\n",
              "      <td>-0.1198</td>\n",
              "      <td>0.2474</td>\n",
              "      <td>0.4036</td>\n",
              "      <td>0.5026</td>\n",
              "      <td>0.6328</td>\n",
              "      <td>0.4948</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>-0.0520</td>\n",
              "      <td>-0.1302</td>\n",
              "      <td>-0.0964</td>\n",
              "      <td>-0.2084</td>\n",
              "      <td>-0.0494</td>\n",
              "      <td>-0.0494</td>\n",
              "      <td>-0.2942</td>\n",
              "      <td>0.0704</td>\n",
              "      <td>0.0546</td>\n",
              "      <td>0.1302</td>\n",
              "      <td>0.5652</td>\n",
              "      <td>0.6848</td>\n",
              "      <td>0.7760</td>\n",
              "      <td>0.9558</td>\n",
              "      <td>0.8542</td>\n",
              "      <td>0.7474</td>\n",
              "      <td>0.6094</td>\n",
              "      <td>0.7708</td>\n",
              "      <td>0.8282</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9974</td>\n",
              "      <td>0.9480</td>\n",
              "      <td>0.7422</td>\n",
              "      <td>0.5678</td>\n",
              "      <td>-0.2196</td>\n",
              "      <td>0.1090</td>\n",
              "      <td>0.5892</td>\n",
              "      <td>0.8768</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9936</td>\n",
              "      <td>0.7852</td>\n",
              "      <td>0.3712</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0228</td>\n",
              "      <td>-0.0910</td>\n",
              "      <td>0.2728</td>\n",
              "      <td>0.8636</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.4318</td>\n",
              "      <td>0.7272</td>\n",
              "      <td>0.6590</td>\n",
              "      <td>0.4090</td>\n",
              "      <td>0.7728</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7272</td>\n",
              "      <td>0.4772</td>\n",
              "      <td>0.4772</td>\n",
              "      <td>0.4772</td>\n",
              "      <td>0.6590</td>\n",
              "      <td>0.1818</td>\n",
              "      <td>0.4318</td>\n",
              "      <td>0.3864</td>\n",
              "      <td>0.8410</td>\n",
              "      <td>0.8864</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>0.2272</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2954</td>\n",
              "      <td>0.2046</td>\n",
              "      <td>0.4772</td>\n",
              "      <td>0.0454</td>\n",
              "      <td>0.2046</td>\n",
              "      <td>0.4318</td>\n",
              "      <td>0.4546</td>\n",
              "      <td>-0.0910</td>\n",
              "      <td>'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.2330</td>\n",
              "      <td>0.2124</td>\n",
              "      <td>0.5014</td>\n",
              "      <td>0.5222</td>\n",
              "      <td>-0.3422</td>\n",
              "      <td>-0.5840</td>\n",
              "      <td>-0.7168</td>\n",
              "      <td>-0.6342</td>\n",
              "      <td>-0.8614</td>\n",
              "      <td>-0.8318</td>\n",
              "      <td>-0.7228</td>\n",
              "      <td>-0.6312</td>\n",
              "      <td>-0.4986</td>\n",
              "      <td>-0.7080</td>\n",
              "      <td>-0.6666</td>\n",
              "      <td>-0.5428</td>\n",
              "      <td>-0.4130</td>\n",
              "      <td>-0.3776</td>\n",
              "      <td>-0.0472</td>\n",
              "      <td>0.1356</td>\n",
              "      <td>0.6136</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9794</td>\n",
              "      <td>0.9352</td>\n",
              "      <td>0.8732</td>\n",
              "      <td>0.9440</td>\n",
              "      <td>0.9588</td>\n",
              "      <td>0.6962</td>\n",
              "      <td>0.4838</td>\n",
              "      <td>0.3982</td>\n",
              "      <td>0.2064</td>\n",
              "      <td>-0.3270</td>\n",
              "      <td>0.0134</td>\n",
              "      <td>0.3620</td>\n",
              "      <td>0.3218</td>\n",
              "      <td>-0.4558</td>\n",
              "      <td>-0.8096</td>\n",
              "      <td>-0.7748</td>\n",
              "      <td>-0.7238</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.8334</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.4286</td>\n",
              "      <td>-0.2540</td>\n",
              "      <td>-0.3650</td>\n",
              "      <td>-0.0952</td>\n",
              "      <td>-0.0794</td>\n",
              "      <td>0.0318</td>\n",
              "      <td>-0.2064</td>\n",
              "      <td>0.0634</td>\n",
              "      <td>0.1112</td>\n",
              "      <td>0.1746</td>\n",
              "      <td>0.2380</td>\n",
              "      <td>0.1904</td>\n",
              "      <td>0.5080</td>\n",
              "      <td>0.5396</td>\n",
              "      <td>0.0318</td>\n",
              "      <td>-0.0158</td>\n",
              "      <td>0.7142</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.4126</td>\n",
              "      <td>-0.0794</td>\n",
              "      <td>-0.0476</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0952</td>\n",
              "      <td>-0.1112</td>\n",
              "      <td>-0.0476</td>\n",
              "      <td>-0.1746</td>\n",
              "      <td>0.0318</td>\n",
              "      <td>-0.0476</td>\n",
              "      <td>0.1112</td>\n",
              "      <td>0.2540</td>\n",
              "      <td>0.1588</td>\n",
              "      <td>-0.4762</td>\n",
              "      <td>'2'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.3808</td>\n",
              "      <td>-0.0096</td>\n",
              "      <td>0.2602</td>\n",
              "      <td>0.2554</td>\n",
              "      <td>-0.4290</td>\n",
              "      <td>-0.6746</td>\n",
              "      <td>-0.6868</td>\n",
              "      <td>-0.6650</td>\n",
              "      <td>-0.8410</td>\n",
              "      <td>-0.9614</td>\n",
              "      <td>-0.7374</td>\n",
              "      <td>-0.7084</td>\n",
              "      <td>-0.6772</td>\n",
              "      <td>-0.6338</td>\n",
              "      <td>-0.6482</td>\n",
              "      <td>-0.6240</td>\n",
              "      <td>-0.3976</td>\n",
              "      <td>-0.5662</td>\n",
              "      <td>-0.2168</td>\n",
              "      <td>0.0458</td>\n",
              "      <td>0.3832</td>\n",
              "      <td>0.6168</td>\n",
              "      <td>0.8988</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9156</td>\n",
              "      <td>0.8796</td>\n",
              "      <td>0.9132</td>\n",
              "      <td>0.7132</td>\n",
              "      <td>0.7590</td>\n",
              "      <td>0.7278</td>\n",
              "      <td>0.5856</td>\n",
              "      <td>0.5060</td>\n",
              "      <td>-0.3710</td>\n",
              "      <td>-0.0868</td>\n",
              "      <td>0.4114</td>\n",
              "      <td>0.3438</td>\n",
              "      <td>-0.1816</td>\n",
              "      <td>-0.5964</td>\n",
              "      <td>-0.6888</td>\n",
              "      <td>-0.6686</td>\n",
              "      <td>...</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.8334</td>\n",
              "      <td>-1</td>\n",
              "      <td>-0.2374</td>\n",
              "      <td>-0.5396</td>\n",
              "      <td>0.1798</td>\n",
              "      <td>0.2086</td>\n",
              "      <td>0.0792</td>\n",
              "      <td>0.0360</td>\n",
              "      <td>0.3238</td>\n",
              "      <td>0.3956</td>\n",
              "      <td>0.4100</td>\n",
              "      <td>0.2662</td>\n",
              "      <td>0.5252</td>\n",
              "      <td>0.3670</td>\n",
              "      <td>0.9136</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.4100</td>\n",
              "      <td>0.1224</td>\n",
              "      <td>0.5252</td>\n",
              "      <td>0.4388</td>\n",
              "      <td>0.0216</td>\n",
              "      <td>-0.0792</td>\n",
              "      <td>0.3812</td>\n",
              "      <td>0.2806</td>\n",
              "      <td>0.0648</td>\n",
              "      <td>-0.0504</td>\n",
              "      <td>-0.0360</td>\n",
              "      <td>-0.1224</td>\n",
              "      <td>0.1366</td>\n",
              "      <td>0.2950</td>\n",
              "      <td>0.0792</td>\n",
              "      <td>-0.0072</td>\n",
              "      <td>0.0936</td>\n",
              "      <td>-0.1510</td>\n",
              "      <td>'2'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.3412</td>\n",
              "      <td>0.0946</td>\n",
              "      <td>0.6082</td>\n",
              "      <td>0.6216</td>\n",
              "      <td>-0.1622</td>\n",
              "      <td>-0.3784</td>\n",
              "      <td>-0.4324</td>\n",
              "      <td>-0.4358</td>\n",
              "      <td>-0.4966</td>\n",
              "      <td>-0.5406</td>\n",
              "      <td>-0.5472</td>\n",
              "      <td>-0.5440</td>\n",
              "      <td>-0.4494</td>\n",
              "      <td>-0.2332</td>\n",
              "      <td>-0.2332</td>\n",
              "      <td>-0.1148</td>\n",
              "      <td>0.0068</td>\n",
              "      <td>0.0778</td>\n",
              "      <td>0.4864</td>\n",
              "      <td>0.9054</td>\n",
              "      <td>0.9560</td>\n",
              "      <td>0.7602</td>\n",
              "      <td>0.7770</td>\n",
              "      <td>0.7636</td>\n",
              "      <td>0.8818</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9426</td>\n",
              "      <td>0.7162</td>\n",
              "      <td>0.5472</td>\n",
              "      <td>0.4122</td>\n",
              "      <td>0.2770</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>-0.4684</td>\n",
              "      <td>-0.1394</td>\n",
              "      <td>0.4210</td>\n",
              "      <td>0.4316</td>\n",
              "      <td>-0.3106</td>\n",
              "      <td>-0.5448</td>\n",
              "      <td>-0.5132</td>\n",
              "      <td>-0.6368</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.0624</td>\n",
              "      <td>0.3438</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>0.6250</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>0.5312</td>\n",
              "      <td>0.4376</td>\n",
              "      <td>0.4688</td>\n",
              "      <td>0.5626</td>\n",
              "      <td>0.5938</td>\n",
              "      <td>0.3438</td>\n",
              "      <td>0.5626</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9376</td>\n",
              "      <td>0.3438</td>\n",
              "      <td>0.2812</td>\n",
              "      <td>-0.0312</td>\n",
              "      <td>0.4376</td>\n",
              "      <td>0.2812</td>\n",
              "      <td>0.1562</td>\n",
              "      <td>0.3124</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>-0.0938</td>\n",
              "      <td>0.1562</td>\n",
              "      <td>0.3124</td>\n",
              "      <td>0.3124</td>\n",
              "      <td>0.2188</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>'3'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 618 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       f1      f2      f3      f4  ...    f615    f616    f617  class\n",
              "0 -0.4394 -0.0930  0.1718  0.4620  ...  0.6410  0.5898 -0.4872    '1'\n",
              "1 -0.4348 -0.1198  0.2474  0.4036  ...  0.4318  0.4546 -0.0910    '1'\n",
              "2 -0.2330  0.2124  0.5014  0.5222  ...  0.2540  0.1588 -0.4762    '2'\n",
              "3 -0.3808 -0.0096  0.2602  0.2554  ... -0.0072  0.0936 -0.1510    '2'\n",
              "4 -0.3412  0.0946  0.6082  0.6216  ...  0.3124  0.2188 -0.2500    '3'\n",
              "\n",
              "[5 rows x 618 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBGMkTSiBDO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d67c51d-dcb1-42c5-dcf7-e9332739ddf5"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7797, 618)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVLg17a5_eK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract the class target variable into a new variable called y using the .pop() method:\n",
        "y = df.pop('class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l45_zZ2E7YF",
        "colab_type": "text"
      },
      "source": [
        "Split the data into tranining ans testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuogNjwu_oVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.3, random_state=188)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqPqDw2gFFXr",
        "colab_type": "text"
      },
      "source": [
        "Instantiate RandomForestClassifier with random_state=42 and then fit the model with the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ydtnIoi_tle",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "8c7d9ca1-4a23-4810-8adb-cf4b2a5a1de5"
      },
      "source": [
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MITRvbEEoPCL",
        "colab_type": "text"
      },
      "source": [
        "Predict the outcome of the training and testing sets with the .predict()method, save the results in a variable called 'train_preds' and 'test_preds'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DNPBjV2_y5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_preds = rf_model.predict(X_train)\n",
        "test_preds = rf_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s54I2_KpR_J",
        "colab_type": "text"
      },
      "source": [
        "Calculate the accuracy score on the training and testing sets, save the result in a variable called train_acc and test_acc respectively and print their values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTKoZxXc_y-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_acc = accuracy_score(y_train, train_preds)\n",
        "test_acc = accuracy_score(y_test, test_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcSr3Qc0_8b8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "65ce3d9e-f703-4342-e211-34baf8617fa2"
      },
      "source": [
        "print(train_acc)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.9320512820512821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUOtMUP6px9Q",
        "colab_type": "text"
      },
      "source": [
        "Our model achieved a perfect accuracy score of 1 on the training set but 0.93 on the testing set. This means our model is overfitting and is not general enough. The ideal situation would be for the model to achieve a very similar, high-accuracy score on both the training and testing sets.\n",
        "\n",
        "As a result of this, we will tune the hyperparameters of our model to get optimal values that will give us high-accuracy score that does not overfit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmrv7QH0ACyg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "f21c2ba2-e3a7-4979-efab-ae86b96cb5a5"
      },
      "source": [
        "# Instantiate another RandomForestClassifier with random_state=42 and n_estimators=20, and then fit the model with the training set:\n",
        "rf_model2 = RandomForestClassifier(random_state=42, n_estimators=20)\n",
        "rf_model2.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0cPEYrZFWbC",
        "colab_type": "text"
      },
      "source": [
        "Make predictions on the training and testing sets with .predict() and save the results into two new variables called train_preds2 and test_preds2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLsRkrkFAS5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b663c705-957e-4756-c365-35be851652a0"
      },
      "source": [
        "train_preds2 = rf_model2.predict(X_train)\n",
        "test_preds2 = rf_model2.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy score for the training and testing sets and save the results in two new variables called train_acc2 and test_acc2:\n",
        "train_acc2 = accuracy_score(y_train, train_preds2)\n",
        "test_acc2 = accuracy_score(y_test, test_preds2)\n",
        "\n",
        "# Print the accuracy scores: train_acc and test_acc:\n",
        "print(train_acc2)\n",
        "print(test_acc2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.9226495726495727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOO9_liLrN7t",
        "colab_type": "text"
      },
      "source": [
        "The accuracy score decreased for the testing sets and now the difference is larger compared to the results from rf_model\n",
        "\n",
        "Instantiate another RandomForestClassifier with random_state=42 and n_estimators=50, and then fit the model with the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GscjpBXZaMuu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "08444596-30a8-4429-eae5-076a93e0a9f5"
      },
      "source": [
        "rf_model3 = RandomForestClassifier(random_state=42, n_estimators=50)\n",
        "rf_model3.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training and testing sets with .predict() and save the results into two new variables called train_preds3 and test_preds3:\n",
        "train_preds3 = rf_model3.predict(X_train)\n",
        "test_preds3 = rf_model3.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy score for the training and testing sets and save the results in two new variables called train_acc3 and test_acc3:\n",
        "train_acc3 = accuracy_score(y_train, train_preds3)\n",
        "test_acc3 = accuracy_score(y_test, test_preds3)\n",
        "\n",
        "# Print the accuracy scores: train_acc3 and test_acc3:\n",
        "print(train_acc3)\n",
        "print(test_acc3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.926923076923077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly_puBC-b3tL",
        "colab_type": "text"
      },
      "source": [
        "This output shows us the model is still overfitting and the rf_model gives a better result compared to rf_model2 and rf_model3. Hence we will take our optimal value for n_estimator to be the default value i.e. 100\n",
        "\n",
        "Now we will proceed to tuning max_depth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFXYJa1ibf40",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0fbf2f15-c9fd-43f8-ddde-87a72bbd26a6"
      },
      "source": [
        "# Instantiate RandomForestClassifier with random_state=42, n_estimators=100, max_depth=5 and then fit the model with the training set:\n",
        "rf_model4 = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=5)\n",
        "rf_model4.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training and testing sets with .predict() and save the results into two new variables called train_preds4 and test_preds4:\n",
        "train_preds4 = rf_model4.predict(X_train)\n",
        "test_preds4 = rf_model4.predict(X_test)\n",
        "# Calculate the accuracy score for the training and testing sets and save the results in two new variables called train_acc4 and test_acc4:\n",
        "train_acc4 = accuracy_score(y_train, train_preds4)\n",
        "test_acc4 = accuracy_score(y_test, test_preds4)\n",
        "# Print the accuracy scores: train_acc4 and test_acc4:\n",
        "print(train_acc4)\n",
        "print(test_acc4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8704416345977644\n",
            "0.8311965811965812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je2zuRUQcpTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0ecb9e79-77bd-4893-cf73-3c29f7f10530"
      },
      "source": [
        "# Instantiate RandomForestClassifier with random_state=42, n_estimators=50, max_depth=10 and then fit the model with the training set:\n",
        "rf_model5 = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
        "rf_model5.fit(X_train, y_train)\n",
        "\n",
        "train_preds5 = rf_model5.predict(X_train)\n",
        "test_preds5 = rf_model5.predict(X_test)\n",
        "train_acc5 = accuracy_score(y_train, train_preds5)\n",
        "test_acc5 = accuracy_score(y_test, test_preds5)\n",
        "print(train_acc5)\n",
        "print(test_acc5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9864394355873191\n",
            "0.9260683760683761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuUsP13qdFN3",
        "colab_type": "text"
      },
      "source": [
        "max_depth=5 gives a better result hence, we will take this as our optimal value for max_depth\n",
        "\n",
        "Now we will proceed to tuning min_leaf_samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "273bBPMldUp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fefeee1a-eb03-4fc4-d0c0-dc7c8aff7f91"
      },
      "source": [
        "# Instantiate RandomForestClassifier with random_state=42, n_estimators=30, max_depth=5, and min_samples_leaf=10, and then fit the model with the training set:\n",
        "rf_model6 = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=5, min_samples_leaf=10)\n",
        "rf_model6.fit(X_train, y_train)\n",
        "\n",
        "train_preds6 = rf_model6.predict(X_train)\n",
        "test_preds6 = rf_model6.predict(X_test)\n",
        "train_acc6 = accuracy_score(y_train, train_preds6)\n",
        "test_acc6 = accuracy_score(y_test, test_preds6)\n",
        "print(train_acc6)\n",
        "print(test_acc6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8697086311159978\n",
            "0.8290598290598291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5sk92yDd9zC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2814fc6e-238c-48a4-95fc-d7acaac28eb8"
      },
      "source": [
        "# Instantiate RandomForestClassifier with random_state=42, n_estimators=30, max_depth=2, and min_samples_leaf=50, and then fit the model with the training set:\n",
        "rf_model7 = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=5, min_samples_leaf=50)\n",
        "rf_model7.fit(X_train, y_train)\n",
        "\n",
        "train_preds7 = rf_model7.predict(X_train)\n",
        "test_preds7 = rf_model7.predict(X_test)\n",
        "train_acc7 = accuracy_score(y_train, train_preds7)\n",
        "test_acc7 = accuracy_score(y_test, test_preds7)\n",
        "print(train_acc7)\n",
        "print(test_acc7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.862561847168774\n",
            "0.8282051282051283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuNrPfOReUJn",
        "colab_type": "text"
      },
      "source": [
        "min_samples_leaf=50 reduces the overfitting, hence this is our optimal value\n",
        "\n",
        "Finally we will proceed to tuning max_features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM87wleZfP9q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c7bd2677-4c0e-4e54-8aee-0ce2ab267768"
      },
      "source": [
        "# Instantiate RandomForestClassifier with random_state=42, n_estimators=30, max_depth=2, and min_samples_leaf=50, max_features=0.5 and then fit the model with the training set:\n",
        "rf_model8 = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=5, min_samples_leaf=50, max_features=0.5)\n",
        "rf_model8.fit(X_train, y_train)\n",
        "\n",
        "train_preds8 = rf_model8.predict(X_train)\n",
        "test_preds8 = rf_model8.predict(X_test)\n",
        "train_acc8 = accuracy_score(y_train, train_preds8)\n",
        "test_acc8 = accuracy_score(y_test, test_preds8)\n",
        "print(train_acc8)\n",
        "print(test_acc8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7425325270295033\n",
            "0.7175213675213675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAlxeZzzf_Ea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c744a0b4-0823-4d32-b9a0-0ddef955a88f"
      },
      "source": [
        "# Instantiate RandomForestClassifier with random_state=42, n_estimators=30, max_depth=2, and min_samples_leaf=50, max_features=0.3 and then fit the model with the training set:\n",
        "rf_model9 = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=5, min_samples_leaf=50, max_features=0.3)\n",
        "rf_model9.fit(X_train, y_train)\n",
        "\n",
        "train_preds9 = rf_model9.predict(X_train)\n",
        "test_preds9 = rf_model9.predict(X_test)\n",
        "train_acc9 = accuracy_score(y_train, train_preds9)\n",
        "test_acc9 = accuracy_score(y_test, test_preds9)\n",
        "print(train_acc9)\n",
        "print(test_acc9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7311709730621221\n",
            "0.697008547008547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ_EaVBUv-nU",
        "colab_type": "text"
      },
      "source": [
        "This final set of hyperparameters still doesn't achieve better results than the one we find with n_estimators=100, max_depth=5, min_samples_leaf=50, max_features=0.5.\n",
        "\n",
        "We built several RandomForest classifier models that accurately predict the letters spoken from audio signals. We tried several values for the hyperparameters n_estimators, max_depth, min_samples_leaf, and max_features. The best combination of hyperparameters we came up with is n_estimators=100, max_depth=5, min_samples_leaf=50, and max_features='0.5'.\n",
        "\n",
        "We achieved a final accuracy score of 0.74 for the training set and 0.71 for the testing set. The model is still slightly overfitting and could still be improved but it is a remarkable result.\n",
        "\n",
        "**Our selected model is rf_model8**"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preparation of Speed Dating Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNdZ4gLW8XtuanwarVXFzU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dotmanjohn/kosh/blob/master/Preparation_of_Speed_Dating_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRv9sL27ohc8",
        "colab_type": "text"
      },
      "source": [
        "#Preparing the Speed Dating Dataset (Data Cleaning)\n",
        "As an entrepreneur, you are planning to launch a new dating app into the market. The key feature that will differentiate your app from other competitors will be your high-performing user-matching algorithm. Before building this model, you have partnered with a speed dating company to collect data from real events. **You just received the dataset from your partner company but realized it is not as clean as you expected; there are missing and incorrect values. Your task is to fix the main data quality issues in this dataset**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rUfVDmGoCtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "file_url = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter11/dataset/Speed_Dating_Data.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJbMozh4o9SO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(file_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYFbc8BwpJED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "c8a1701f-1102-4ec2-b510-9d488b20ba4e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iid</th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>match</th>\n",
              "      <th>int_corr</th>\n",
              "      <th>samerace</th>\n",
              "      <th>age_o</th>\n",
              "      <th>race_o</th>\n",
              "      <th>pf_o_att</th>\n",
              "      <th>pf_o_sin</th>\n",
              "      <th>pf_o_int</th>\n",
              "      <th>pf_o_fun</th>\n",
              "      <th>pf_o_amb</th>\n",
              "      <th>pf_o_sha</th>\n",
              "      <th>dec_o</th>\n",
              "      <th>attr_o</th>\n",
              "      <th>sinc_o</th>\n",
              "      <th>intel_o</th>\n",
              "      <th>fun_o</th>\n",
              "      <th>amb_o</th>\n",
              "      <th>shar_o</th>\n",
              "      <th>like_o</th>\n",
              "      <th>prob_o</th>\n",
              "      <th>met_o</th>\n",
              "      <th>age</th>\n",
              "      <th>field</th>\n",
              "      <th>field_cd</th>\n",
              "      <th>undergra</th>\n",
              "      <th>mn_sat</th>\n",
              "      <th>tuition</th>\n",
              "      <th>race</th>\n",
              "      <th>...</th>\n",
              "      <th>amb5_2</th>\n",
              "      <th>you_call</th>\n",
              "      <th>them_cal</th>\n",
              "      <th>date_3</th>\n",
              "      <th>numdat_3</th>\n",
              "      <th>num_in_3</th>\n",
              "      <th>attr1_3</th>\n",
              "      <th>sinc1_3</th>\n",
              "      <th>intel1_3</th>\n",
              "      <th>fun1_3</th>\n",
              "      <th>amb1_3</th>\n",
              "      <th>shar1_3</th>\n",
              "      <th>attr7_3</th>\n",
              "      <th>sinc7_3</th>\n",
              "      <th>intel7_3</th>\n",
              "      <th>fun7_3</th>\n",
              "      <th>amb7_3</th>\n",
              "      <th>shar7_3</th>\n",
              "      <th>attr4_3</th>\n",
              "      <th>sinc4_3</th>\n",
              "      <th>intel4_3</th>\n",
              "      <th>fun4_3</th>\n",
              "      <th>amb4_3</th>\n",
              "      <th>shar4_3</th>\n",
              "      <th>attr2_3</th>\n",
              "      <th>sinc2_3</th>\n",
              "      <th>intel2_3</th>\n",
              "      <th>fun2_3</th>\n",
              "      <th>amb2_3</th>\n",
              "      <th>shar2_3</th>\n",
              "      <th>attr3_3</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Law</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Law</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.16</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Law</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Law</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Law</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 195 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   iid   id  gender  idg  condtn  ...  attr5_3  sinc5_3  intel5_3  fun5_3  amb5_3\n",
              "0    1  1.0       0    1       1  ...      NaN      NaN       NaN     NaN     NaN\n",
              "1    1  1.0       0    1       1  ...      NaN      NaN       NaN     NaN     NaN\n",
              "2    1  1.0       0    1       1  ...      NaN      NaN       NaN     NaN     NaN\n",
              "3    1  1.0       0    1       1  ...      NaN      NaN       NaN     NaN     NaN\n",
              "4    1  1.0       0    1       1  ...      NaN      NaN       NaN     NaN     NaN\n",
              "\n",
              "[5 rows x 195 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5wYhdQvpcIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b43d76c-d933-4759-a95c-477db8a43df6"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8378, 195)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2lEhA3opmox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4767a17-1159-4583-dbfe-1f6eaabc131f"
      },
      "source": [
        "# Print out the number of duplicate rows\n",
        "df.duplicated().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMu-UsBbqFxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "599c0bc8-b9ed-4101-8cd4-4a9e282a9778"
      },
      "source": [
        "# Print out the number of duplicate rows, but this time only look at the identifier columns\n",
        "df.loc[df.duplicated(), ['iid', 'id', 'partner', 'pid']].sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "iid        0.0\n",
              "id         0.0\n",
              "partner    0.0\n",
              "pid        0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkhMqN0bsCVY",
        "colab_type": "text"
      },
      "source": [
        "Looking at the dataset description document, we know that the values of the following variables should range between 1 and 10: 'imprace', 'imprelig', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy', and 'satis_2'. In the next few steps, we are going to check that there are no unexpected values in these columns.\n",
        "\n",
        "Create a variable called scale_1_10. This will list the following column names: 'imprace', 'imprelig', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy', and 'satis_2':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfMQlYRgsEqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scale_1_10 = ['imprace', 'imprelig', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming',\n",
        "              'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy', 'satis_2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KnmO4ZJsatw",
        "colab_type": "text"
      },
      "source": [
        "Create a function called check_range that takes a column (a pandas series), a minimum value, and a maximum value as input parameters. The function will check whether each row of the given column is outside the given range (below the minimum value or above the maximum value) and return the corresponding list of binary values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAYwu2wnscxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_range(column, min_value, max_value):\n",
        "  return (column < min_value) | (column >max_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtntxuM0tHdc",
        "colab_type": "text"
      },
      "source": [
        "Test the function on the imprace column with 1 and 10 as the minimum and maximum values, respectively. Then, save the output into a variable called unexpected_mask and print the sum to check how many cases are outside this range:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNAx-c7OtJNR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47901805-f526-403f-d8a2-a7c384b47d84"
      },
      "source": [
        "unexpected_mask = check_range(df['imprace'], 1, 10)\n",
        "unexpected_mask.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4knE3tNuO3l",
        "colab_type": "text"
      },
      "source": [
        "Define a function called print_unexpected that takes a DataFrame, a column name, and a list of binary values as input parameters. This function will check whether the sum of the binary values is over 0. If it is, the case prints out the column name, this sum, and the unique values of the given columns and the rows that match the binary list (keeping only True values) using the pandas .loc and .unique() methods:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKLj8c2KuQua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_unexpected(df, col_name, unexpected_mask):\n",
        "  if unexpected_mask.sum() > 0:\n",
        "    print(col_name)\n",
        "    print(unexpected_mask.sum())\n",
        "    print(df.loc[unexpected_mask,col_name].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRIHipL5uXHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8dbcc6e7-1c12-40da-e204-c9164be5e47a"
      },
      "source": [
        "# Test your function on the 'imprace' column using the output of the previous function, that is, unexpected_mask:\n",
        "print_unexpected(df, 'imprace', unexpected_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imprace\n",
            "8\n",
            "[0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJTe_qSXuxzE",
        "colab_type": "text"
      },
      "source": [
        "Create a function called check_ranges that takes a DataFrame, a list of columns, and minimum and maximum values as input parameters. This function will iterate through each column from the given column list, call the check_range function, and pass its output to the print_unexpected function, which was earlier defined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XNnOEiXu0IH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_ranges(df, col_list, min_value, max_value):\n",
        "  for col_name in col_list:\n",
        "    unexpected_mask = check_range(df[col_name], min_value, max_value)\n",
        "    print_unexpected(df, col_name, unexpected_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7UWNJGuu7Ct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "b3eb5702-d4cd-4046-bd0b-ae9685e54896"
      },
      "source": [
        "# Test this function with the dataset and the scale_1_10 variables you defined in step 9 , and use 1 and 10 as their minimum and maximum values, respectively:\n",
        "check_ranges(df, scale_1_10, 1, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imprace\n",
            "8\n",
            "[0.]\n",
            "museums\n",
            "18\n",
            "[0.]\n",
            "art\n",
            "18\n",
            "[0.]\n",
            "hiking\n",
            "18\n",
            "[0.]\n",
            "gaming\n",
            "137\n",
            "[14.  0.]\n",
            "clubbing\n",
            "18\n",
            "[0.]\n",
            "reading\n",
            "51\n",
            "[13.]\n",
            "theater\n",
            "18\n",
            "[0.]\n",
            "movies\n",
            "18\n",
            "[0.]\n",
            "concerts\n",
            "18\n",
            "[0.]\n",
            "yoga\n",
            "36\n",
            "[0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LXWS5wdvleY",
        "colab_type": "text"
      },
      "source": [
        "Create a function called replace_value that takes a DataFrame, a column name,an incorrect value, and a new value as input parameters. This function will subset all the rows that are equal to the incorrect value for the given column and replace it with the new given value. Then, it will print out the column's name and the list of unique values for this column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx9TTbdbvnKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_value(df, col_name, incorrect_value, new_value):\n",
        "  df.loc[df[col_name] == incorrect_value, col_name] = new_value\n",
        "  print(col_name)\n",
        "  print(df[col_name].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZkacKQfvr9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "af196ee7-d74a-4b6a-8181-8388be5ec747"
      },
      "source": [
        "# Test the replace_value function on the gaming column, where 14 is the incorrect value and 10 is the new value:\n",
        "replace_value(df, 'gaming', 14, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gaming\n",
            "[ 1.  5.  4.  6.  2.  3.  7.  8. 10. nan  9.  0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_9dF4Zyv6Q6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3a267958-f1bb-4a93-c878-f51dac9285fc"
      },
      "source": [
        "# Use the replace_value function on the reading column, where 13 is the incorrect value and 10 is the new value:\n",
        "replace_value(df, 'reading', 13, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading\n",
            "[ 6. 10.  7.  9.  8.  4.  5. nan  2.  3.  1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBq6zJHGyHf7",
        "colab_type": "text"
      },
      "source": [
        "Create a for loop that will iterate through the following suffixes: ['1_1', '1_2', '1_3', '1_s', '2_1', '2_2', '2_3', '4_1', '4_2', '4_3', '7_2', and '7_3']. For each of them, create a list comprehension (or another for loop) so that we can extract the columns that contain the given suffix by using the .endswith() method and store them into a variable called suffix_cols. Then, apply the check_ranges function to this list and use 0 and 100 as their minimum and maximum values, respectively:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3byNg-wnyJ1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for suffix in ['1_1', '1_2', '1_3', '1_s', '2_1', '2_2', '2_3', '4_1', '4_2', '4_3', '7_2', '7_3']:\n",
        "  suffix_cols = [col for col in df.columns if col.endswith(suffix)]\n",
        "  check_ranges(df, suffix_cols, 0, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRY76-UYyRO7",
        "colab_type": "text"
      },
      "source": [
        "No output is displayed, which means that all these columns have values within the expected range, that is, between 0 and 100.\n",
        "\n",
        "Create a for loop that's similar to what we created above for the following suffixes, where 1 and 10 are the minimum and maximum values, respectively: ['3_1', '3_2', '3_3', '5_1', '5_2', '5_3', '3_s']:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UjMzLTRyUQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "960f5ddd-18ac-4524-9dad-eeaf2882375f"
      },
      "source": [
        "for suffix in ['3_1', '3_2', '3_3', '5_1', '5_2', '5_3', '3_s']:\n",
        "  suffix_cols = [col for col in df.columns if col.endswith(suffix)]\n",
        "  check_ranges(df, suffix_cols, 1, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attr3_3\n",
            "112\n",
            "[12.]\n",
            "sinc3_3\n",
            "173\n",
            "[12.]\n",
            "intel3_3\n",
            "233\n",
            "[12.]\n",
            "fun3_3\n",
            "153\n",
            "[12.]\n",
            "amb3_3\n",
            "147\n",
            "[12.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqEmPfJCyqXV",
        "colab_type": "text"
      },
      "source": [
        "As we can see, all the columns ending with 3_3 have 12 as their unexpected values. Let's say that, after consultation with the surveyors, we agree to replace these values with 10.\n",
        "\n",
        "Create a for loop that iterates through the list of columns ending with 3_3 and call the replace_values function for each of them. Provide 12 as the incorrect value and 10 as the new value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v44x8ZVysP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "1c4e2e55-b0d0-4162-c128-b73ce3f57c04"
      },
      "source": [
        "for col_name in ['attr3_3', 'sinc3_3', 'intel3_3', 'fun3_3', 'amb3_3']:\n",
        "  replace_value(df, col_name, 12, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attr3_3\n",
            "[ 5.  7. nan  6.  4.  9.  8.  3. 10.  2.]\n",
            "sinc3_3\n",
            "[ 7.  6. nan  5.  8.  9. 10.  4.  3.  2.]\n",
            "intel3_3\n",
            "[ 7.  9. nan  6. 10.  8.  5.  4.  3.]\n",
            "fun3_3\n",
            "[ 7.  9. nan  8.  6.  3.  5. 10.  2.  4.]\n",
            "amb3_3\n",
            "[ 7.  4. nan  5. 10.  9.  8.  6.  2.  3.  1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrQDjsrqy5y_",
        "colab_type": "text"
      },
      "source": [
        "We have fixed the unexpected values for these columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_PyJ0o8y72V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "d4fd57ff-5c31-4972-ecdd-9ae38f72dcaa"
      },
      "source": [
        "# Print the data type of each variable using the dtypes attribute:\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "iid           int64\n",
              "id          float64\n",
              "gender        int64\n",
              "idg           int64\n",
              "condtn        int64\n",
              "             ...   \n",
              "attr5_3     float64\n",
              "sinc5_3     float64\n",
              "intel5_3    float64\n",
              "fun5_3      float64\n",
              "amb5_3      float64\n",
              "Length: 195, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehLTdMlJzIVv",
        "colab_type": "text"
      },
      "source": [
        "As we can see, most of the columns have been detected as numerical variables, but by looking at the dataset description document, we know that most of them are categorical. So we change their data types.\n",
        "\n",
        "Create a list called num_cols that contains the following list of columns: 'round', 'order', 'int_corr', 'age', 'mn_sat', 'income', and 'expnum'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtBsitpfzK-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cols = ['round', 'order', 'int_corr', 'age', 'mn_sat', 'income', 'expnum']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM09LAJjkuM5",
        "colab_type": "text"
      },
      "source": [
        "Create another list called cat_cols that contains the remaining column names (excluding the ones in num_cols) of this DataFrame using the attribute columns combined with the .difference() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0iZzSqNzQV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_cols = df.columns.difference(num_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAsOgYgBk3Dt",
        "colab_type": "text"
      },
      "source": [
        "Create a for loop that will iterate through cat_cols and change the data type for each column into a category by using the .astype() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nD704StzYTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col_name in cat_cols:\n",
        "  df[col_name] = df[col_name].astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AjvIq-5zfM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "df615808-558a-403a-ea1d-a507a971a0ab"
      },
      "source": [
        "# Print the data type of each variable using the dtypes attribute:\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "iid         category\n",
              "id          category\n",
              "gender      category\n",
              "idg         category\n",
              "condtn      category\n",
              "              ...   \n",
              "attr5_3     category\n",
              "sinc5_3     category\n",
              "intel5_3    category\n",
              "fun5_3      category\n",
              "amb5_3      category\n",
              "Length: 195, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IIoSKxVzvGE",
        "colab_type": "text"
      },
      "source": [
        "We have sorted out the data types for each column. Now, let's see whether we have any missing columns in the numerical fields."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6a8VLVrzujX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "b861cb9b-973e-425d-d3b3-2aa982a76993"
      },
      "source": [
        "# Print the number of missing values for each column in num_cols by combining the .isna() and .sum() methods:\n",
        "df[num_cols].isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "round          0\n",
              "order          0\n",
              "int_corr     158\n",
              "age           95\n",
              "mn_sat      5245\n",
              "income      4099\n",
              "expnum      6578\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8TUPJCo0442",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "8f2ee815-3591-4de9-ca8d-ad9be8d88151"
      },
      "source": [
        "# Print the unique values of the 'int_corr' variable using the .unique() method:\n",
        "df['int_corr'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.14,  0.54,  0.16,  0.61,  0.21,  0.25,  0.34,  0.5 ,  0.28,\n",
              "       -0.36,  0.29,  0.18,  0.1 , -0.21,  0.32,  0.73,  0.6 ,  0.07,\n",
              "        0.11,  0.39, -0.24, -0.14,  0.09, -0.04, -0.3 , -0.26, -0.15,\n",
              "       -0.47, -0.18,  0.05,  0.37,  0.35,  0.15, -0.19, -0.43,  0.  ,\n",
              "       -0.17,  0.08, -0.16,  0.06, -0.05, -0.13, -0.06,  0.33, -0.51,\n",
              "        0.12,  0.19,  0.47,  0.03,  0.46,  0.43,  0.52, -0.46, -0.27,\n",
              "        0.59,  0.31, -0.34, -0.03, -0.11,  0.42, -0.4 , -0.23,  0.17,\n",
              "        0.68, -0.01, -0.35,  0.3 ,  0.65,  0.24,  0.41,  0.49,  0.01,\n",
              "        0.22, -0.08,  0.27,  0.44,  0.62, -0.2 , -0.02, -0.33, -0.52,\n",
              "       -0.1 ,  0.58, -0.57, -0.31, -0.07, -0.32,  0.04, -0.12,  0.48,\n",
              "       -0.22, -0.29,  0.38,  0.53, -0.38,  0.02, -0.28,  0.13,  0.2 ,\n",
              "         nan, -0.41, -0.44,  0.51, -0.48,  0.4 ,  0.26,  0.77, -0.49,\n",
              "       -0.25, -0.09,  0.45, -0.39,  0.83,  0.57, -0.61,  0.72, -0.37,\n",
              "        0.23, -0.58,  0.8 , -0.56,  0.63, -0.63,  0.71,  0.36,  0.56,\n",
              "        0.55,  0.76,  0.69,  0.79,  0.9 ,  0.67,  0.66,  0.81,  0.64,\n",
              "        0.74,  0.75,  0.85, -0.42, -0.5 , -0.59,  0.7 ,  0.82,  0.78,\n",
              "       -0.45, -0.83,  0.88, -0.7 , -0.62, -0.55,  0.87,  0.91,  0.84,\n",
              "       -0.64, -0.73, -0.54])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R_Bdr441BcJ",
        "colab_type": "text"
      },
      "source": [
        "The values of the int_corr column range between -1 and 1. It seems like they have been normalized. Since there are no extreme values or outliers, we can impute the missing values with the mean of this variable. This is what we are going to do in the next few steps.\n",
        "\n",
        "Create a condition mask called int_corr_mask that finds the missing values in the 'int_corr' column by using the .isna() method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFVIDGdE1DmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_corr_mask = df['int_corr'].isna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs5ttHyB1KEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d2e06b5-5e95-4851-cc0d-6a9802826127"
      },
      "source": [
        "# Display the number of missing values for this column by using the .sum() method on int_corr_mask:\n",
        "int_corr_mask.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mFIFexBlfoq",
        "colab_type": "text"
      },
      "source": [
        "Extract the mean of int_corr using the .mean() method and store it in a new variable called int_corr_mean. Print out its value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TCSZA2m1VHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f22b16c4-48f7-4d7d-d460-cbdbefeff523"
      },
      "source": [
        "int_corr_mean = df['int_corr'].mean()\n",
        "print(int_corr_mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.19600973236009664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p11h_981Z5p",
        "colab_type": "text"
      },
      "source": [
        "The average value for this column is 0.196. We need to replace all the missing values with this value in the int_corr column.\n",
        "\n",
        "Replace all the missing values in the int_corr variable with their averages by using the .fillna() method along with the inplace=True parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr7YBEsr1b2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['int_corr'].fillna(int_corr_mean, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LRWo1Tm1iCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30e152d0-a444-4d52-9dd9-9b16b37b9e0a"
      },
      "source": [
        "# Print the number of missing values for int_corr by combining the .isna() and .sum() methods:\n",
        "df['int_corr'].isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg2ZaTOxl4i5",
        "colab_type": "text"
      },
      "source": [
        "Create a new variable called missing_num_cols that contains the following columns: age, mn_sat, income, and expnum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "busiNmmN1oEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_num_cols = ['age', 'mn_sat', 'income', 'expnum']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAFPeR7ll_ay",
        "colab_type": "text"
      },
      "source": [
        "Create a for loop that will iterate through the columns in missing_num_cols and print out their names and a list of their unique values using the .unique() method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4LjSJjW1sSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "outputId": "e7eee7fe-1a2e-4b00-d243-b4dad098f1ad"
      },
      "source": [
        "for col_name in missing_num_cols:\n",
        "  print(col_name)\n",
        "  print(df[col_name].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age\n",
            "[21. 24. 25. 23. 22. 26. 27. 30. 28. nan 29. 34. 35. 32. 39. 20. 19. 18.\n",
            " 37. 33. 36. 31. 42. 38. 55.]\n",
            "mn_sat\n",
            "[  nan 1070. 1258. 1400. 1290. 1460. 1430. 1215. 1330. 1450. 1155. 1140.\n",
            " 1360. 1402. 1250. 1210. 1220. 1410. 1260. 1380. 1030. 1309. 1308. 1050.\n",
            " 1100. 1310. 1490. 1188. 1097. 1212. 1340. 1034. 1185. 1242. 1160. 1099.\n",
            " 1214. 1270. 1110. 1178. 1060. 1157. 1180. 1014. 1341.  990. 1320. 1159.\n",
            " 1370. 1105. 1365. 1011. 1130. 1206. 1331. 1191.  914. 1200. 1080. 1090.\n",
            " 1092. 1470. 1149. 1134. 1230. 1267. 1280. 1227. 1239.]\n",
            "income\n",
            "[ 69487.  65929.     nan  37754.  86340.  60304.  54620.  48652.  29237.\n",
            "  56580.  36782.  38548.  52010.  28418.  43185.  23152.  43664.  48441.\n",
            "  61152.  36485.  41507.  17134.  30038.  33772.  24997.  42096.  28891.\n",
            "  62635.  12063.  29809.  26482.  30147.  39919.  41466.  23988.  28989.\n",
            "  50948.  38022.  47559.  53539.  32159.  53940.  40753.  38207.  46166.\n",
            "  30973.  28317.  26645.  25589.  55223. 109031.  40409.  21597.  76624.\n",
            "  35968.  51725.  55419.  55550.  26682.  41547.  23361.  74893.  52804.\n",
            "  53923.  27094.  57213.  42390.  43636.  57887.  30768.  66699.  45360.\n",
            "  55080.  17378.  40375.  48929.  78193.  63351.  50745.  29279.  38774.\n",
            "  58802.  41831.  52186.  97857.  74624.  21590.  38832.  37248.  28240.\n",
            "  53771.  56096.  31560.  52467.  80006.  47572.  22439.  31383.  40749.\n",
            "  47997.  78704.  31143.  32129.  44195.  46837.  97972.  35960.  65708.\n",
            "  49466.  53229.  32649.  35867.  40244.  42640.  52388.  62875.  30855.\n",
            "  46800.  45695.  46792.  53501.  64716.  27248.  22805.  56118.  30146.\n",
            "  39123.  46153.  45300.  42397.  44346.  42225.  37405.  28524.  61141.\n",
            "   8607.  41476.  49841.  37240.  36594.  62997.  46608.  37881.  48944.\n",
            "  77112.  18283.  31432.  73073.  26706.  50060.  25401.  80608.  43844.\n",
            "  53196.  25786.  39394.  40695.  45788.  37315.  51663.  32563.  54303.\n",
            "  16908.  39729.  57316.  30587.  57513.  31857.  23207.  25831.  28759.\n",
            "  19264.  41778.  35963.  49409.  31516.  36223.  43367.  27503.  35187.\n",
            "  26298.  31148.  55704.  46138.  66827.  42897.  31809.  75347.  47005.\n",
            "  52805.  50725.  65693.  45736.  33906.  50501.  48785.  52318.  62844.\n",
            "  52586.  29236.  31486.  31632. 106663.  84043.  35224.  36381.  65498.\n",
            "  60000.  22669.  81266.  29746.  47556.  42651.  27794.  41737.  90225.\n",
            "  52280.  56056.  60835.  62829.  16767.  42967.  21488.  89977.  18619.\n",
            "  22161.  82734.  40163.  46185.  78844.  29575.  34752.  22173.  37994.\n",
            "  35409.  23707.  57501.  25314.  48876.  34870.  35848.  45017.  12416.\n",
            "  87789.  50572.  49642.  20000.  32508.  35627.  46280.  41191.  71787.\n",
            "  72412.  36510.  32386.  15863.  46272.  48137.  61686.  47624.  36673.\n",
            "  55138.]\n",
            "expnum\n",
            "[ 2.  5. 10.  3. 15. 20.  4.  9. 19.  0. nan  8. 12.  1.  7.  6. 18. 14.\n",
            " 13.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CdL2bki13Ka",
        "colab_type": "text"
      },
      "source": [
        "The values for these columns haven't been normalized and some of them have outliers. This time, we are going to need to use their medians to fill in the missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VQStLm916-r",
        "colab_type": "text"
      },
      "source": [
        "Create a for loop, calculate the median of each column and save it into a variable called col_median. Then, impute the missing values with this median value by using the .fillna() method along with the inplace=True parameter and print the name of the column and its median value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6rf64Hq16c4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "6f80ac24-1eb0-44cb-e512-ba8323be1e44"
      },
      "source": [
        "for col_name in missing_num_cols:\n",
        "  col_median = df[col_name].median()\n",
        "  df[col_name].fillna(col_median, inplace=True)\n",
        "  print(col_name)\n",
        "  print(col_median)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age\n",
            "26.0\n",
            "mn_sat\n",
            "1310.0\n",
            "income\n",
            "43185.0\n",
            "expnum\n",
            "4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJAI-rC9nCeo",
        "colab_type": "text"
      },
      "source": [
        "Create a for loop, print the name of each column and its number of missing values by combining the .isna() and .sum() methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afX7eQVb2DwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "36bef831-7ce7-4b2e-9771-a205d41294f3"
      },
      "source": [
        "for col_name in missing_num_cols:\n",
        "  print(col_name)\n",
        "  print(df[col_name].isna().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age\n",
            "0\n",
            "mn_sat\n",
            "0\n",
            "income\n",
            "0\n",
            "expnum\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7LkVyHLnQWM",
        "colab_type": "text"
      },
      "source": [
        "We have cleaned up most of the main quality issues in this dataset. We looked for duplication, incorrect values, incorrect data types, and missing values. We are now more confident in using this modified version of the dataset to build a matching algorithm if we really were to work on this project."
      ]
    }
  ]
}